{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Database\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Database().dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Level', 'Health', 'Energy', 'Sanity']]\n",
    "y = df['Rarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Health</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Sanity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1020.000000</td>\n",
       "      <td>1020.000000</td>\n",
       "      <td>1020.000000</td>\n",
       "      <td>1020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.956863</td>\n",
       "      <td>40.260196</td>\n",
       "      <td>40.308108</td>\n",
       "      <td>40.267461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.481573</td>\n",
       "      <td>34.754796</td>\n",
       "      <td>34.862985</td>\n",
       "      <td>34.811319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>1.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>16.090000</td>\n",
       "      <td>16.195000</td>\n",
       "      <td>16.027500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>28.460000</td>\n",
       "      <td>28.965000</td>\n",
       "      <td>28.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>54.077500</td>\n",
       "      <td>54.225000</td>\n",
       "      <td>53.867500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>187.260000</td>\n",
       "      <td>190.750000</td>\n",
       "      <td>186.360000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Level       Health       Energy       Sanity\n",
       "count  1020.000000  1020.000000  1020.000000  1020.000000\n",
       "mean      7.956863    40.260196    40.308108    40.267461\n",
       "std       4.481573    34.754796    34.862985    34.811319\n",
       "min       1.000000     1.120000     1.090000     1.610000\n",
       "25%       4.000000    16.090000    16.195000    16.027500\n",
       "50%       7.000000    28.460000    28.965000    28.630000\n",
       "75%      11.000000    54.077500    54.225000    53.867500\n",
       "max      20.000000   187.260000   190.750000   186.360000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 75, 'max_samples': 0.9, 'max_depth': 15}\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "parameters_rf = {\n",
    "    'n_estimators': [25, 50, 75, 100, 150, 200],\n",
    "    'max_depth': [10, 15, 30, 50, 80],\n",
    "    'max_samples': [0.5, 0.75, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "search_rf = RandomizedSearchCV(model_rf, parameters_rf, n_iter=5, cv=5, random_state=42)\n",
    "search_rf.fit(X_train, y_train)\n",
    "model_rf_ = search_rf.best_estimator_\n",
    "print(search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9607843137254902"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, model_rf_.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 75, 'max_depth': 15}\n"
     ]
    }
   ],
   "source": [
    "model_gb = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "parameters_gb = {\n",
    "    'n_estimators': [25, 50, 75, 100, 150, 200],\n",
    "    'max_depth': [10, 15, 30, 50, 80]\n",
    "}\n",
    "\n",
    "search_gb = RandomizedSearchCV(model_gb, parameters_gb, n_iter=5, cv=5, random_state=42)\n",
    "search_gb.fit(X_train, y_train)\n",
    "model_gb_ = search_gb.best_estimator_\n",
    "print(search_gb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9117647058823529"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, model_gb_.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 10, 'alpha': 75}\n"
     ]
    }
   ],
   "source": [
    "model_r = RidgeClassifier(random_state=42)\n",
    "\n",
    "parameters_r = {\n",
    "    'alpha': [1, 5, 10, 25, 50, 75, 100, 150, 200],\n",
    "    'max_iter': [10, 15, 30, 50, 80]\n",
    "}\n",
    "\n",
    "search_r = RandomizedSearchCV(model_r, parameters_r, n_iter=5, cv=5, random_state=42)\n",
    "search_r.fit(X_train, y_train)\n",
    "model_r_ = search_r.best_estimator_\n",
    "print(search_r.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4852941176470588"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, model_r_.predict(X_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The model with the best accuracy after tuning was the Random Forest Classifier model. This is an ensemble model made of decision trees that uses bagging. Decision trees are a weaker model that arrive at a prediction by going through a series of splits called leaf nodes that evaluate the sample. In an ensemble model of decision trees, a collection of decision trees are trained to better fit the data. Bagging is a method used in ensemble training where each weaker model can be trained in parallel using different samples of the dataset. I tuned my model using a randomized parameter search, which tests several given parameter combinations for accuracy. I tested for 'n_estimators' (the amount of weak learners used), 'max_depth' (the maximum depth of leaf nodes each weak learner is allowed to reach), and 'max_samples' (the maximum percentage of samples from the dataset each weak learner can be trained on). It determined that the most accurate Random Forest model most likely has these parameters: 75 'n_estimators', 90% 'max_samples', and 'max_depth' of 15."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BandersnatchStarter-H0MCPdpT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
